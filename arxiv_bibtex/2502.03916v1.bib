@article{2502.03916v1,
  title={ Experiments with Large Language Models on Retrieval-Augmented Generation for Closed-Source Simulation Software },
  author={ Andreas Baumann and Peter Eberhard },
  year={ 2025 },
  journal={ arXiv preprint arXiv:2502.03916v1 },
  url={ http://arxiv.org/abs/2502.03916v1 },
  eprint={ 2502.03916v1 },
  archivePrefix={arXiv},
  primaryClass={ cs.CL },
  pdf={ http://arxiv.org/pdf/2502.03916v1 },
  abstract={ Large Language Models (LLMs) are increasingly helpful in text generation, even writing code in programming languages based on user prompts written in natural language. They are even applied to generate simulation models for multibody systems from natural language. Research results suggest that LLMs surpass the mere replication of existing code examples, where some LLMs have been trained on an open-source multibody simulation code. However, for closed-source simulation software, such results are not to be expected as their ideas and concepts might differ from other publicly available ones. LLMs can hallucinate for knowledge-intensive tasks, such as model creation, which can lead to wrong responses. This is especially the case for the LLM unknown closed-source simulation software. The same applies to other internal knowledge kept private to protect intellectual property or data privacy. The Retrieval-Augmented Generation (RAG) approach might yield a solution for these knowledge-intensive tasks. This paper explores the application of RAG to closed-source simulation software and presents first experiments. After a brief introduction to LLMs, the RAG approach, and the simulation method applied by the close-source simulation software, several examples are provided to test LLMs' knowledge of the simulation software and the creation of simulation models using two RAG systems. The examples show promising results indicating the benefits of applying RAG systems to closed-source simulation software, helping to access their knowledge. Nevertheless, they also reveal gaps in the applied information and open questions for further research. }
}
