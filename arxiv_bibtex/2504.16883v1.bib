@article{2504.16883v1,
  title={ Enhancing Critical Thinking with AI: A Tailored Warning System for RAG Models },
  author={ Xuyang Zhu and Sejoon Chang and Andrew Kuik },
  year={ 2025 },
  journal={ arXiv preprint arXiv:2504.16883v1 },
  url={ http://arxiv.org/abs/2504.16883v1 },
  eprint={ 2504.16883v1 },
  archivePrefix={arXiv},
  primaryClass={ cs.HC },
  pdf={ http://arxiv.org/pdf/2504.16883v1 },
  abstract={ Retrieval-Augmented Generation (RAG) systems offer a powerful approach to enhancing large language model (LLM) outputs by incorporating fact-checked, contextually relevant information. However, fairness and reliability concerns persist, as hallucinations can emerge at both the retrieval and generation stages, affecting users' reasoning and decision-making. Our research explores how tailored warning messages -- whose content depends on the specific context of hallucination -- shape user reasoning and actions in an educational quiz setting. Preliminary findings suggest that while warnings improve accuracy and awareness of high-level hallucinations, they may also introduce cognitive friction, leading to confusion and diminished trust in the system. By examining these interactions, this work contributes to the broader goal of AI-augmented reasoning: developing systems that actively support human reflection, critical thinking, and informed decision-making rather than passive information consumption. }
}
